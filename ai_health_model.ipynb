{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49194d4-bed5-4127-8020-157c59f8fd2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f840649a-8236-42ed-b183-ad31a5b293a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loding data\n",
    "metadata = pd.read_csv('data/HAM10000_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0a5a1ef-c6e7-468b-96f4-47ed9c844ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     lesion_id      image_id   dx dx_type   age   sex localization\n",
       "0  HAM_0000118  ISIC_0027419  bkl   histo  80.0  male        scalp\n",
       "1  HAM_0000118  ISIC_0025030  bkl   histo  80.0  male        scalp\n",
       "2  HAM_0002730  ISIC_0026769  bkl   histo  80.0  male        scalp\n",
       "3  HAM_0002730  ISIC_0025661  bkl   histo  80.0  male        scalp\n",
       "4  HAM_0001466  ISIC_0031633  bkl   histo  75.0  male          ear"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28244d34-4641-4b3a-910e-0f48cfb39430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loding images\n",
    "def load_and_preprocess_image(image_path, target_size=(224, 224)):\n",
    "    image = load_img(image_path, target_size=target_size)\n",
    "    image = img_to_array(image)\n",
    "    image = image / 255.0\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4909a383-4ca2-476a-a1fd-f71e5f3517b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8012 validated image filenames belonging to 7 classes.\n",
      "Found 2003 validated image filenames belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "# Split the dataset\n",
    "train_df, val_df = train_test_split(metadata, test_size=0.2, random_state=42)\n",
    "\n",
    "# Image data generator with augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=90\n",
    ")\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Directory of the images\n",
    "image_dir = 'data/HAM10000_images'\n",
    "\n",
    "# Create a function to load images from directory\n",
    "def load_image(image_id):\n",
    "    return os.path.join(image_dir, f\"{image_id}.jpg\")\n",
    "\n",
    "# Add file path to the DataFrame\n",
    "train_df['image_path'] = train_df['image_id'].apply(load_image)\n",
    "val_df['image_path'] = val_df['image_id'].apply(load_image)\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow_from_dataframe(\n",
    "    train_df,\n",
    "    x_col='image_path',\n",
    "    y_col='dx',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_dataframe(\n",
    "    val_df,\n",
    "    x_col='image_path',\n",
    "    y_col='dx',\n",
    "    target_size=(224, 224),\n",
    "    class_mode='categorical',\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Get the number of classes\n",
    "num_classes = len(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014b71ab-cd56-472b-b216-77af705cbdb3",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c6e38fe7-ea57-401a-af15-682d3d3829a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "9406464/9406464 [==============================] - 9s 1us/step\n",
      "Epoch 1/20\n",
      "251/251 [==============================] - 326s 1s/step - loss: 0.9082 - accuracy: 0.7032 - val_loss: 0.8361 - val_accuracy: 0.7134\n",
      "Epoch 2/20\n",
      "251/251 [==============================] - 289s 1s/step - loss: 0.7267 - accuracy: 0.7420 - val_loss: 0.7450 - val_accuracy: 0.7374\n",
      "Epoch 3/20\n",
      "251/251 [==============================] - 299s 1s/step - loss: 0.6770 - accuracy: 0.7552 - val_loss: 0.7517 - val_accuracy: 0.7394\n",
      "Epoch 4/20\n",
      "251/251 [==============================] - 282s 1s/step - loss: 0.6591 - accuracy: 0.7596 - val_loss: 0.7612 - val_accuracy: 0.7169\n",
      "Epoch 5/20\n",
      "251/251 [==============================] - 292s 1s/step - loss: 0.6296 - accuracy: 0.7742 - val_loss: 0.7350 - val_accuracy: 0.7299\n",
      "Epoch 6/20\n",
      "251/251 [==============================] - 287s 1s/step - loss: 0.6084 - accuracy: 0.7807 - val_loss: 0.7197 - val_accuracy: 0.7404\n",
      "Epoch 7/20\n",
      "251/251 [==============================] - 286s 1s/step - loss: 0.6056 - accuracy: 0.7792 - val_loss: 0.7406 - val_accuracy: 0.7269\n",
      "Epoch 8/20\n",
      "251/251 [==============================] - 270s 1s/step - loss: 0.5866 - accuracy: 0.7923 - val_loss: 0.7166 - val_accuracy: 0.7499\n",
      "Epoch 9/20\n",
      "251/251 [==============================] - 288s 1s/step - loss: 0.5630 - accuracy: 0.7941 - val_loss: 0.7145 - val_accuracy: 0.7514\n",
      "Epoch 10/20\n",
      "251/251 [==============================] - 273s 1s/step - loss: 0.5570 - accuracy: 0.7939 - val_loss: 0.7414 - val_accuracy: 0.7304\n",
      "Epoch 11/20\n",
      "251/251 [==============================] - 310s 1s/step - loss: 0.5270 - accuracy: 0.8095 - val_loss: 0.7232 - val_accuracy: 0.7489\n",
      "Epoch 12/20\n",
      "251/251 [==============================] - 300s 1s/step - loss: 0.5159 - accuracy: 0.8132 - val_loss: 0.7089 - val_accuracy: 0.7539\n",
      "Epoch 13/20\n",
      "251/251 [==============================] - 301s 1s/step - loss: 0.5000 - accuracy: 0.8186 - val_loss: 0.7232 - val_accuracy: 0.7524\n",
      "Epoch 14/20\n",
      "251/251 [==============================] - 295s 1s/step - loss: 0.4968 - accuracy: 0.8180 - val_loss: 0.7666 - val_accuracy: 0.7279\n",
      "Epoch 15/20\n",
      "251/251 [==============================] - 305s 1s/step - loss: 0.4845 - accuracy: 0.8194 - val_loss: 0.7649 - val_accuracy: 0.7349\n",
      "Epoch 16/20\n",
      "251/251 [==============================] - 280s 1s/step - loss: 0.4739 - accuracy: 0.8273 - val_loss: 0.8244 - val_accuracy: 0.7314\n",
      "Epoch 17/20\n",
      "251/251 [==============================] - 270s 1s/step - loss: 0.4650 - accuracy: 0.8299 - val_loss: 0.8264 - val_accuracy: 0.7189\n",
      "Epoch 1/10\n",
      "251/251 [==============================] - 305s 1s/step - loss: 0.8241 - accuracy: 0.7278 - val_loss: 1.2987 - val_accuracy: 0.7104\n",
      "Epoch 2/10\n",
      "251/251 [==============================] - 305s 1s/step - loss: 0.5868 - accuracy: 0.7879 - val_loss: 1.3398 - val_accuracy: 0.7184\n",
      "Epoch 3/10\n",
      "251/251 [==============================] - 292s 1s/step - loss: 0.5161 - accuracy: 0.8089 - val_loss: 0.9121 - val_accuracy: 0.7184\n",
      "Epoch 4/10\n",
      "251/251 [==============================] - 280s 1s/step - loss: 0.4576 - accuracy: 0.8299 - val_loss: 0.7989 - val_accuracy: 0.7464\n",
      "Epoch 5/10\n",
      "251/251 [==============================] - 318s 1s/step - loss: 0.4147 - accuracy: 0.8486 - val_loss: 0.8474 - val_accuracy: 0.7604\n",
      "Epoch 6/10\n",
      "251/251 [==============================] - 272s 1s/step - loss: 0.3823 - accuracy: 0.8586 - val_loss: 1.1775 - val_accuracy: 0.7484\n",
      "Epoch 7/10\n",
      "251/251 [==============================] - 367s 1s/step - loss: 0.3548 - accuracy: 0.8688 - val_loss: 0.8597 - val_accuracy: 0.7818\n",
      "Epoch 8/10\n",
      "251/251 [==============================] - 358s 1s/step - loss: 0.3208 - accuracy: 0.8816 - val_loss: 0.6340 - val_accuracy: 0.7983\n",
      "Epoch 9/10\n",
      "251/251 [==============================] - 362s 1s/step - loss: 0.3024 - accuracy: 0.8875 - val_loss: 0.6141 - val_accuracy: 0.7993\n",
      "Epoch 10/10\n",
      "251/251 [==============================] - 369s 1s/step - loss: 0.2787 - accuracy: 0.8987 - val_loss: 0.8437 - val_accuracy: 0.7339\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "\n",
    "\n",
    "# Load the MobileNetV2 model\n",
    "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Freeze the layers of the base model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define callbacks\n",
    "checkpoint = ModelCheckpoint('mobilenetv2_skin_cancer.keras', monitor='val_accuracy', save_best_only=True, mode='max')\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', patience=5, mode='max')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_generator, epochs=20, validation_data=val_generator, callbacks=[checkpoint, early_stopping])\n",
    "\n",
    "# Unfreeze some layers and fine-tune\n",
    "for layer in base_model.layers[-50:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training\n",
    "history_fine = model.fit(train_generator, epochs=10, validation_data=val_generator, callbacks=[checkpoint, early_stopping])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3538af6f-ed8f-4b76-bf82-dc448086402a",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d05ae983-3201-4acf-a87d-a584a0693010",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/63 [==============================] - 36s 568ms/step - loss: 0.6141 - accuracy: 0.7993\n",
      "Validation Accuracy: 79.93%\n"
     ]
    }
   ],
   "source": [
    "# Load the best model\n",
    "model.load_weights('mobilenetv2_skin_cancer.keras')\n",
    "\n",
    "# Evaluate on validation set\n",
    "val_loss, val_accuracy = model.evaluate(val_generator)\n",
    "print(f'Validation Accuracy: {val_accuracy * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f264b4-b94a-463b-b48a-c9050be6a72c",
   "metadata": {},
   "source": [
    "# Web app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "787b9285-ac4b-4087-b325-6575a4f1c5d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "# Assuming you have a loaded model\n",
    "model = load_model('mobilenetv2_skin_cancer.keras')\n",
    "\n",
    "# Save the model to the correct path\n",
    "model.save('C:/Users/HP\\Desktop/ai health web/mobilenetv2_skin_cancer.h5')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e82d17-3e0a-4158-974b-8317217b3eff",
   "metadata": {},
   "source": [
    "# web try "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2529204-501b-4fc1-be37-0ca15a4922b9",
   "metadata": {},
   "source": [
    "# Web try 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10c3c8aa-5e62-457a-9beb-43fc2069307a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on http://127.0.0.1:5000\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [29/Jun/2024 13:50:19] \"GET / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Jun/2024 13:50:21] \"GET / HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 22s 22s/step\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "1/1 [==============================] - 0s 407ms/step\n",
      "1/1 [==============================] - 41s 41s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Jun/2024 13:51:15] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Jun/2024 13:51:15] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Jun/2024 13:51:15] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [29/Jun/2024 13:51:15] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 84ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [29/Jun/2024 13:55:22] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, request, jsonify, render_template_string\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import threading\n",
    "from io import BytesIO\n",
    "\n",
    "# Define the Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load your pre-trained model\n",
    "model = load_model('mobilenetv2_skin_cancer.keras')\n",
    "\n",
    "# Assuming you have a mapping of class indices to labels and recommendations\n",
    "labels = {\n",
    "    0: 'akiec', \n",
    "    1: 'bcc', \n",
    "    2: 'bkl', \n",
    "    3: 'df', \n",
    "    4: 'mel', \n",
    "    5: 'nv', \n",
    "    6: 'vasc'\n",
    "}\n",
    "\n",
    "recommendations = {\n",
    "    'akiec': \"Actinic keratosis: Precancerous condition; consult a dermatologist for treatment options.\",\n",
    "    'bcc': \"Basal cell carcinoma: Seek medical advice for treatment options.\",\n",
    "    'bkl': \"Benign keratosis: Usually harmless but monitor for changes. Consult a dermatologist if needed.\",\n",
    "    'df': \"Dermatofibroma: Generally benign; consult a dermatologist if there are concerns.\",\n",
    "    'mel': \"Melanoma: Consult a dermatologist immediately for further evaluation and treatment.\",\n",
    "    'nv': \"Nevus (mole): Generally benign, but keep an eye on changes in size, shape, or color.\",\n",
    "    'vasc': \"Vascular lesion: Generally benign; consult a dermatologist if there are concerns.\"\n",
    "}\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template_string('''\n",
    "    <!DOCTYPE html>\n",
    "    <html>\n",
    "    <head>\n",
    "        <title>Skin Lesion Detection</title>\n",
    "    </head>\n",
    "    <body>\n",
    "        <h1>Upload a skin lesion image for detection</h1>\n",
    "        <form id=\"predictionForm\" enctype=\"multipart/form-data\">\n",
    "            <input type=\"file\" id=\"inputData\" name=\"file\">\n",
    "            <button type=\"button\" onclick=\"makePrediction()\">Predict</button>\n",
    "        </form>\n",
    "        <h2>Prediction:</h2>\n",
    "        <div id=\"result\"></div>\n",
    "\n",
    "        <script>\n",
    "            function makePrediction() {\n",
    "                const formData = new FormData();\n",
    "                formData.append('file', document.getElementById('inputData').files[0]);\n",
    "                \n",
    "                fetch('/predict', {\n",
    "                    method: 'POST',\n",
    "                    body: formData\n",
    "                })\n",
    "                .then(response => response.text())  // Changed to text() to receive HTML response\n",
    "                .then(data => {\n",
    "                    document.getElementById('result').innerHTML = data;  // Update innerHTML with response\n",
    "                })\n",
    "                .catch(error => {\n",
    "                    console.error('Error:', error);\n",
    "                });\n",
    "            }\n",
    "        </script>\n",
    "    </body>\n",
    "    </html>\n",
    "    ''')\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    # Get the file from the POST request\n",
    "    if 'file' not in request.files:\n",
    "        return jsonify({'error': 'No file part'}), 400\n",
    "    \n",
    "    file = request.files['file']\n",
    "    if file.filename == '':\n",
    "        return jsonify({'error': 'No selected file'}), 400\n",
    "    \n",
    "    try:\n",
    "        # Load and preprocess the image\n",
    "        img = image.load_img(BytesIO(file.read()), target_size=(224, 224))\n",
    "        img_array = image.img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "        img_array /= 255.0\n",
    "\n",
    "        # Make predictions\n",
    "        predictions = model.predict(img_array)\n",
    "        predicted_class = np.argmax(predictions, axis=1)\n",
    "\n",
    "        # Ensure predicted_class is in the range of labels keys\n",
    "        if predicted_class[0] not in labels:\n",
    "            return jsonify({'error': f'Invalid prediction class index {predicted_class[0]}'}), 500\n",
    "        \n",
    "        label = labels[predicted_class[0]]\n",
    "        recommendation = recommendations.get(label, 'No recommendation found')\n",
    "\n",
    "        # Render HTML response with prediction and recommendation\n",
    "        return render_template_string('''\n",
    "            <h3>Prediction: {{ prediction }}</h3>\n",
    "            <p>Recommendation: {{ recommendation }}</p>\n",
    "        ''', prediction=label, recommendation=recommendation)\n",
    "\n",
    "    except Exception as e:\n",
    "        return jsonify({'error': str(e)}), 500\n",
    "\n",
    "def run_app():\n",
    "    app.run(port=5000)\n",
    "\n",
    "# Run the Flask app in a separate thread\n",
    "flask_thread = threading.Thread(target=run_app)\n",
    "flask_thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "580c044a-6474-48a2-a062-920105b4a2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip list > installed_libraries.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7afd9b8b-a9ff-4551-b1dd-417341e0a23e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
